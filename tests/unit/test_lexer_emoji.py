"""Tests for emoji and unicode symbol support in lexer identifiers (GH#186).

OCTAVE supports mythic compression style using emoji and unicode symbols as keys.
This enables expressive, semantic markup like:

    âš ï¸::AT[ARM.result]â†’MUST_READ[skill_selectors]

Current behavior: E005 - Unexpected character: 'âš '
Expected behavior: Parse as valid IDENTIFIER token.

Implementation approach:
- Use Python's unicodedata module to check character categories
- Allow Letter (L*), Symbol Other (So), and specific Math Symbols (Sm)
- Exclude symbols that are OCTAVE operators (â†’, âŠ•, â‡Œ, âˆ§, âˆ¨, Â§, etc.)
- Handle multi-codepoint emoji gracefully (document as limited support)
"""

import unicodedata

import pytest

from octave_mcp.core.lexer import LexerError, TokenType, tokenize


class TestEmojiIdentifiers:
    """Test emoji support as identifier starts and characters."""

    def test_warning_emoji_as_identifier(self):
        """Warning sign should be valid identifier start.

        Input: âš ï¸::warning_message
        Expected: IDENTIFIER('âš ï¸'), ASSIGN, IDENTIFIER
        """
        tokens, _ = tokenize("âš ï¸::warning_message")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸"
        assert tokens[1].type == TokenType.ASSIGN
        assert tokens[2].type == TokenType.IDENTIFIER
        assert tokens[2].value == "warning_message"

    def test_checkmark_emoji_as_identifier(self):
        """Checkmark should be valid identifier."""
        tokens, _ = tokenize("âœ“::PASSED")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âœ“"
        assert tokens[1].type == TokenType.ASSIGN

    def test_cross_mark_emoji_as_identifier(self):
        """Cross mark should be valid identifier."""
        tokens, _ = tokenize("âœ—::FAILED")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âœ—"

    def test_star_emoji_as_identifier(self):
        """Star emoji should be valid identifier."""
        tokens, _ = tokenize("â­::PRIORITY")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "â­"

    def test_fire_emoji_as_identifier(self):
        """Fire emoji should be valid identifier."""
        tokens, _ = tokenize("ðŸ”¥::CRITICAL")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "ðŸ”¥"

    def test_emoji_in_list(self):
        """Emoji identifiers should work in lists."""
        tokens, _ = tokenize("STATUS::[âœ“,âœ—,âš ï¸]")
        identifiers = [t for t in tokens if t.type == TokenType.IDENTIFIER]
        # STATUS, âœ“, âœ—, âš ï¸
        emoji_ids = [t for t in identifiers if ord(t.value[0]) > 127]
        assert len(emoji_ids) >= 3

    def test_emoji_mixed_with_ascii(self):
        """Emoji can be combined with ASCII in identifiers."""
        tokens, _ = tokenize("âš ï¸_warning::message")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸_warning"

    def test_emoji_at_end_of_identifier(self):
        """Emoji can appear at end of identifier."""
        tokens, _ = tokenize("status_âš ï¸::warning")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "status_âš ï¸"

    def test_multiple_emoji_identifier(self):
        """Multiple emoji in sequence should work."""
        tokens, _ = tokenize("âš ï¸â­::urgent_priority")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸â­"


class TestUnicodeSymbolIdentifiers:
    """Test unicode symbol support as identifiers (non-operator symbols)."""

    def test_bullet_point_identifier(self):
        """Bullet point should be valid identifier."""
        tokens, _ = tokenize("â€¢::item")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "â€¢"

    def test_arrow_bullet_identifier(self):
        """Arrow bullet should be valid identifier (not flow operator)."""
        tokens, _ = tokenize("â–¸::action")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "â–¸"

    def test_box_drawing_identifier(self):
        """Box drawing characters should be valid."""
        tokens, _ = tokenize("â”œ::tree_branch")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "â”œ"

    def test_circled_numbers_identifier(self):
        """Circled numbers should work as identifiers."""
        tokens, _ = tokenize("â‘ ::first_step")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "â‘ "

    def test_mathematical_subscript(self):
        """Mathematical subscripts should work."""
        tokens, _ = tokenize("xâ‚::value")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "xâ‚"


class TestOperatorSymbolsNotIdentifiers:
    """Ensure OCTAVE operators remain operators, not identifiers."""

    def test_flow_arrow_remains_operator(self):
        """â†’ (U+2192) should remain FLOW operator."""
        tokens, _ = tokenize("Aâ†’B")
        flow_tokens = [t for t in tokens if t.type == TokenType.FLOW]
        assert len(flow_tokens) == 1
        assert flow_tokens[0].value == "â†’"

    def test_synthesis_remains_operator(self):
        """âŠ• (U+2295) should remain SYNTHESIS operator."""
        tokens, _ = tokenize("AâŠ•B")
        synth_tokens = [t for t in tokens if t.type == TokenType.SYNTHESIS]
        assert len(synth_tokens) == 1

    def test_tension_remains_operator(self):
        """â‡Œ (U+21CC) should remain TENSION operator."""
        tokens, _ = tokenize("Aâ‡ŒB")
        tension_tokens = [t for t in tokens if t.type == TokenType.TENSION]
        assert len(tension_tokens) == 1

    def test_constraint_remains_operator(self):
        """âˆ§ (U+2227) should remain CONSTRAINT operator."""
        tokens, _ = tokenize("[Aâˆ§B]")
        constraint_tokens = [t for t in tokens if t.type == TokenType.CONSTRAINT]
        assert len(constraint_tokens) == 1

    def test_alternative_remains_operator(self):
        """âˆ¨ (U+2228) should remain ALTERNATIVE operator."""
        tokens, _ = tokenize("[Aâˆ¨B]")
        alt_tokens = [t for t in tokens if t.type == TokenType.ALTERNATIVE]
        assert len(alt_tokens) == 1

    def test_section_remains_operator(self):
        """Â§ (U+00A7) should remain SECTION operator."""
        tokens, _ = tokenize("Â§1::OVERVIEW")
        section_tokens = [t for t in tokens if t.type == TokenType.SECTION]
        assert len(section_tokens) == 1

    def test_concat_remains_operator(self):
        """â§º (U+29FA) should remain CONCAT operator."""
        tokens, _ = tokenize("Aâ§ºB")
        concat_tokens = [t for t in tokens if t.type == TokenType.CONCAT]
        assert len(concat_tokens) == 1


class TestMultiCodepointEmoji:
    """Test handling of multi-codepoint emoji (ZWJ sequences, skin tones).

    Multi-codepoint emoji like ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ (family) or ðŸ‘ðŸ½ (thumbs up with skin tone)
    consist of multiple Unicode codepoints joined by ZWJ or modifiers.

    Approach: We support what Python's regex can reasonably handle.
    Complex ZWJ sequences may split into components, which is acceptable.
    """

    def test_simple_emoji_with_variation_selector(self):
        """Warning sign with variation selector (âš ï¸ = U+26A0 U+FE0F)."""
        tokens, _ = tokenize("âš ï¸::warning")
        assert tokens[0].type == TokenType.IDENTIFIER
        # Should preserve the full sequence including variation selector
        assert "âš " in tokens[0].value

    def test_emoji_with_skin_tone_modifier(self):
        """Emoji with skin tone modifier should work reasonably.

        Note: Behavior with skin tones may vary. The key is no crash.
        """
        # ðŸ‘ðŸ½ = U+1F44D U+1F3FD (thumbs up + medium skin tone)
        try:
            tokens, _ = tokenize("ðŸ‘ðŸ½::approved")
            # If it works, first token should be an identifier
            assert tokens[0].type == TokenType.IDENTIFIER
        except LexerError:
            # If it raises, that's acceptable for complex emoji
            # as long as the error is clear
            pytest.skip("Skin tone modifiers not supported in identifiers")

    def test_zwj_sequence_family_emoji(self):
        """Family emoji (ZWJ sequence) should be handled gracefully.

        Note: ZWJ sequences are complex. We document limited support.
        """
        # ðŸ‘¨â€ðŸ‘©â€ðŸ‘§ = man + ZWJ + woman + ZWJ + girl
        try:
            tokens, _ = tokenize("ðŸ‘¨â€ðŸ‘©â€ðŸ‘§::family_group")
            # If it works, check it doesn't crash
            assert tokens[0].type == TokenType.IDENTIFIER
        except LexerError:
            # ZWJ sequences may not be fully supported
            pytest.skip("ZWJ emoji sequences not supported in identifiers")

    def test_flag_emoji(self):
        """Flag emoji (regional indicator pairs) may have limited support."""
        # ðŸ‡ºðŸ‡¸ = U+1F1FA U+1F1F8 (US flag)
        try:
            tokens, _ = tokenize("ðŸ‡ºðŸ‡¸::country")
            assert tokens[0].type == TokenType.IDENTIFIER
        except LexerError:
            pytest.skip("Flag emoji not supported in identifiers")


class TestEmojiInValues:
    """Test emoji work in value positions (strings, identifiers)."""

    def test_emoji_in_quoted_string(self):
        """Emoji should work fine in quoted strings."""
        tokens, _ = tokenize('MESSAGE::"Status: âš ï¸ Warning"')
        string_token = [t for t in tokens if t.type == TokenType.STRING][0]
        assert "âš ï¸" in string_token.value

    def test_emoji_in_list_values(self):
        """Emoji identifiers should work as list values."""
        tokens, _ = tokenize("ICONS::[â­, ðŸ”¥, âœ“]")
        identifiers = [t for t in tokens if t.type == TokenType.IDENTIFIER and ord(t.value[0]) > 127]
        assert len(identifiers) >= 3

    def test_emoji_after_flow_operator(self):
        """Emoji should work after flow operator."""
        tokens, _ = tokenize("STARTâ†’âš ï¸â†’END")
        identifiers = [t for t in tokens if t.type == TokenType.IDENTIFIER]
        assert len(identifiers) == 3
        assert "âš ï¸" in [t.value for t in identifiers]


class TestEmojiEdgeCases:
    """Test edge cases and boundary conditions for emoji support."""

    def test_emoji_only_identifier(self):
        """Single emoji should be valid identifier."""
        tokens, _ = tokenize("âš ï¸")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸"

    def test_emoji_with_numbers(self):
        """Emoji followed by numbers should work."""
        tokens, _ = tokenize("âš ï¸123::warning_level")
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸123"

    def test_number_followed_by_emoji_is_separate_tokens(self):
        """Numbers followed by emoji tokenize as separate tokens.

        In OCTAVE, 123âš ï¸ is valid as NUMBER(123) IDENTIFIER(âš ï¸).
        This is different from traditional languages where this would be an error.
        """
        tokens, _ = tokenize("123âš ï¸")
        # Should have NUMBER and IDENTIFIER as separate tokens
        number_tokens = [t for t in tokens if t.type == TokenType.NUMBER]
        identifier_tokens = [t for t in tokens if t.type == TokenType.IDENTIFIER]
        assert len(number_tokens) == 1
        assert number_tokens[0].value == 123
        assert len(identifier_tokens) == 1
        assert identifier_tokens[0].value == "âš ï¸"

    def test_emoji_does_not_break_line_tracking(self):
        """Multi-byte emoji should not break line/column tracking."""
        content = """LINE1::âš ï¸
LINE2::value"""
        tokens, _ = tokenize(content)
        line2_tokens = [t for t in tokens if t.line == 2]
        assert len(line2_tokens) > 0
        line2_identifier = [t for t in line2_tokens if t.type == TokenType.IDENTIFIER][0]
        assert line2_identifier.value == "LINE2"
        assert line2_identifier.column == 1

    def test_emoji_column_tracking(self):
        """Column tracking should work correctly with emoji."""
        tokens, _ = tokenize("âš ï¸::value")
        assign_token = [t for t in tokens if t.type == TokenType.ASSIGN][0]
        # âš ï¸ may be 1 or 2 characters depending on variation selector
        # The key is that column is >= 2 (after the emoji)
        assert assign_token.column >= 2

    def test_emoji_in_complex_expression(self):
        """Emoji should work in complex OCTAVE expressions."""
        # Note: Use @ symbol for AT operator, not "AT" word
        content = "âš ï¸::@[ARM.result]â†’MUST_READ[skill_selectors]"
        tokens, _ = tokenize(content)
        # Should tokenize without error
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸"
        # Should have AT token (@ symbol)
        at_tokens = [t for t in tokens if t.type == TokenType.AT]
        assert len(at_tokens) >= 1
        # Should have FLOW token
        flow_tokens = [t for t in tokens if t.type == TokenType.FLOW]
        assert len(flow_tokens) >= 1

    def test_nfc_normalization_preserves_emoji(self):
        """NFC normalization should not break emoji."""
        # Some emoji may have different normalization forms
        content = "âš ï¸::test"
        normalized_content = unicodedata.normalize("NFC", content)
        tokens, _ = tokenize(normalized_content)
        assert tokens[0].type == TokenType.IDENTIFIER


class TestMythicCompressionStyle:
    """Integration tests for mythic compression patterns.

    These test real-world usage patterns from OCTAVE mythic compression.
    """

    def test_warning_annotation(self):
        """Warning annotation pattern from issue #186."""
        content = "âš ï¸::AT[ARM.result]â†’MUST_READ[skill_selectors]"
        tokens, _ = tokenize(content)
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "âš ï¸"

    def test_status_indicators(self):
        """Status indicator pattern."""
        content = "STATUS::[âœ“_complete, âš ï¸_warning, âœ—_failed]"
        tokens, _ = tokenize(content)
        identifiers = [t for t in tokens if t.type == TokenType.IDENTIFIER]
        # Should have STATUS and three status indicators
        assert len([t for t in identifiers if t.value.startswith("âœ“")]) >= 1
        assert len([t for t in identifiers if "âš ï¸" in t.value]) >= 1
        assert len([t for t in identifiers if t.value.startswith("âœ—")]) >= 1

    def test_priority_markers(self):
        """Priority marker pattern."""
        content = """â­::high_priority
ðŸ”¥::critical_priority
ðŸ“Œ::pinned"""
        tokens, _ = tokenize(content)
        emoji_identifiers = [t for t in tokens if t.type == TokenType.IDENTIFIER and ord(t.value[0]) > 127]
        assert len(emoji_identifiers) >= 3

    def test_section_with_emoji_marker(self):
        """Section with emoji marker should work."""
        content = "Â§1::âš ï¸_WARNINGS"
        tokens, _ = tokenize(content)
        section_tokens = [t for t in tokens if t.type == TokenType.SECTION]
        assert len(section_tokens) == 1
        # The value after section should be an identifier with emoji
        identifiers = [t for t in tokens if t.type == TokenType.IDENTIFIER]
        emoji_ids = [t for t in identifiers if "âš ï¸" in t.value]
        assert len(emoji_ids) >= 1
